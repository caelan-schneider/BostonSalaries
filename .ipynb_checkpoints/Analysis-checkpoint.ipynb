{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 1000) \n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purpose: create our dataframe\n",
    "\n",
    "#default column headers\n",
    "col_headers = ['Name', 'Department', 'Title', 'Regular', 'Retro', 'Other', 'Overtime', 'Injured', 'Detail', 'Quinn', 'Total', 'Postal']\n",
    "\n",
    "#create an empty df with default values\n",
    "earnings_df = pd.DataFrame(columns = col_headers)\n",
    "\n",
    "#add column 'Year' and set to NaN\n",
    "earnings_df['Year'] = np.nan\n",
    "\n",
    "for year in range(2011, 2020):\n",
    "    \n",
    "    #read in the CSV for the given year, set it to variable next_df\n",
    "    next_df = pd.read_csv('./data/salaries_' + str(year) + '.csv', skiprows=1, names=col_headers, encoding='latin1')\n",
    "    \n",
    "    #add the column 'Year' to next_df and set to the given year\n",
    "    next_df['Year'] = year\n",
    "    \n",
    "    #in the 2013 and 2014 datasets, title and department columns are in the wrong order\n",
    "    if year == 2013 or year == 2014:\n",
    "        \n",
    "        #get the list of columns (including year)\n",
    "        col_list = list(next_df)\n",
    "        \n",
    "        #swap the order of title and department in the list\n",
    "        col_list[1], col_list[2] = col_list[2], col_list[1]\n",
    "        \n",
    "        #set the dataframe's columns to the new list\n",
    "        next_df.columns = col_list\n",
    "    \n",
    "    #add next_df to earnings_df\n",
    "    earnings_df = pd.concat([earnings_df, next_df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_df[['Department', 'Name', 'Title', 'Postal']].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purpose: clean our dataframe\n",
    "\n",
    "#targeted (hard-coded) cleaning for specific rows\n",
    "earnings_df = earnings_df.loc[earnings_df['Department']!='DEPARTMENT_NAME']\n",
    "earnings_df.loc[earnings_df['Department'] == 'Boston Cntr-Youth & Families', 'Department'] = 'Boston Cntr - Youth & Families'\n",
    "earnings_df.loc[earnings_df['Department'] == 'DND Neighborhood Development', 'Department'] = 'Neighborhood Development'\n",
    "earnings_df.loc[earnings_df['Name'].str.match('Ostiguy,David M'), 'Postal'] = '02327'\n",
    "earnings_df.loc[earnings_df['Name'].str.match('Karales,George Alfred'), 'Postal'] = '02170'\n",
    "earnings_df.loc[earnings_df['Name'].str.match('Smith,Kenneth J'), 'Postal'] = '02124'\n",
    "earnings_df.loc[earnings_df['Name'].str.match('Thomas,Sarita J'), 'Postal'] = '02125'\n",
    "earnings_df.loc[earnings_df['Name'].str.match('Morris,Judith A.'), 'Postal'] = '02170'\n",
    "earnings_df.loc[earnings_df['Name'].str.match('Mendez,Jose R'), 'Postal'] = '02135'\n",
    "earnings_df.loc[earnings_df['Name'].str.match('Morrison,June'), 'Postal'] = '02481'\n",
    "\n",
    "#dimensions are qualitative columns, facts are quantitative columns\n",
    "facts = ['Regular', 'Retro', 'Other', 'Overtime', 'Injured', 'Detail', 'Quinn', 'Total']\n",
    "    \n",
    "##cast year to type 'int'\n",
    "earnings_df['Year'] = earnings_df['Year'].astype(int)\n",
    "\n",
    "#clean the facts columns and convert from type 'object' to 'float'\n",
    "earnings_df[facts] = earnings_df[facts].astype(str).applymap(lambda x: x.strip())\n",
    "earnings_df[facts] = earnings_df[facts].replace({'^-$|^None$|^nan$|\\)':0, ',':'', '\\$':'', ' ':'', '^\\(':'-'}, regex=True)\n",
    "earnings_df[facts] = earnings_df[facts].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dimensions from type 'object' to 'string' and remove leading/trailing whitespace\n",
    "dimensions = ['Name', 'Department', 'Title', 'Postal']\n",
    "earnings_df[dimensions] = earnings_df[dimensions].astype(str)\n",
    "\n",
    "#purpose: clean Postal column\n",
    "\n",
    "#add a 0 to the front of any code with 4 digits\n",
    "mask = earnings_df['Postal'].str.len() == 4\n",
    "earnings_df.loc[mask, 'Postal'] = '0' + earnings_df.loc[mask, 'Postal']\n",
    "\n",
    "#remove delivery route number from any codes that have it (number after hyphen)\n",
    "earnings_df['Postal'] = earnings_df['Postal'].str.split('-', expand=True)[0]\n",
    "\n",
    "#any postal codes with non-numeric characters will be set to UNKNOWN\n",
    "earnings_df.loc[earnings_df['Postal'].str.match('[A-Z]', na=False), 'Postal'] = 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purpose: clean Name column\n",
    "earnings_df['Name'] = earnings_df['Name'].replace({'\\.':''}, regex=True).str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purpose: clean Title column\n",
    "earnings_df['Title'] = earnings_df['Title'].replace({'\\.':'', '(?<=[a-z])([A-Z])':r' \\1', '\\(':' (', '\\)':') ', '\\/':' & ', '&':' & ', ',':'', '\\#':''}, regex=True).str.upper()\n",
    "earnings_df[dimensions] = earnings_df[dimensions].applymap(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_df[['Department', 'Name', 'Title', 'Postal']].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrevs = {\n",
    "    'ADMIN':'ADMINISTRATIVE',\n",
    "    'OFFC':'OFFICER',\n",
    "    'OFFCR':'OFFICER',\n",
    "    '\\(DET\\)':'DETECTIVE',\n",
    "    'DET':'DETECTIVE',\n",
    "    'SUPV':'SUPERVISOR',\n",
    "    'SPV':'SUPERVISOR',\n",
    "    'EXEC':'EXECUTIVE',\n",
    "    'ANL':'ANALYST',\n",
    "    'ANAL':'ANALYST',\n",
    "    'TECH':'TECHNICIAN',\n",
    "    'EQUIP OPER':'EQUIPMENT OPERATOR',\n",
    "    'PROJ':'PROJECT',\n",
    "    'SP PROJ STFF':'SPECIAL PROJECT STAFF',\n",
    "    'SP PROJECT STFF':'SPECIAL PROJECT STAFF',\n",
    "    'STFF':'STAFF',\n",
    "    'ACAD':'ACADEMY',\n",
    "    'INSTR':'INSTRUCTOR',\n",
    "    'ASST':'ASSISTANT',\n",
    "    'ASSIST':'ASSISTANT',\n",
    "    'DEP':'DEPUTY',\n",
    "    'SUPN':'SUPERINTENDENT',\n",
    "    'SYS':'SYSTEMS',\n",
    "    'COOR':'COORDINATOR',\n",
    "    'COORD':'COORDINATOR',\n",
    "    'SEC':'SECRETARY',\n",
    "    'LIEUT':'LIEUTENANT',\n",
    "    'MAINT':'MAINTENANCE',\n",
    "    'DIR':'DIRECTOR',\n",
    "    'MGMT':'MANAGEMENT',\n",
    "    'MGR':'MANAGER',\n",
    "    'MNGR':'MANAGER',\n",
    "    'MANGR':'MANAGER',\n",
    "    'MED':'MEDICAL',\n",
    "    'OPER':'OPERATIONS',\n",
    "    'DATA PROC':'DATA PROCESSING',\n",
    "    'CORP COUNSEL':'CORPORATION COUNSEL',\n",
    "    'ASSOC':'ASSOCIATE',\n",
    "    'COMM SERV':'COMMUNITY SERVICE',\n",
    "    'COMM':'COMMUNICATIONS',\n",
    "    'COMMUNIC':'COMMUNICATIONS',\n",
    "    'COMMUN':'COMMUNICATIONS',\n",
    "    'BLDG':'BUILDING',\n",
    "    'SERV':'SERVICE',\n",
    "    'REG VOTERS':'REGISTRAR OF VOTERS',\n",
    "    'SVC':'SERVICE',\n",
    "    'SRV':'SERVICE',\n",
    "    'EQUIP':'EQUIPMENT',\n",
    "    'PRIN':'PRINCIPAL',\n",
    "    'DIST':'DISTRICT',\n",
    "    'FF':'FIRE FIGHTER',\n",
    "    'INSTRUC':'INSTRUCTOR',\n",
    "    'SR':'SENIOR',\n",
    "    'JR':'JUNIOR',\n",
    "    'MECH':'MECHANIC',\n",
    "    'MECHA':'MECHANIC',\n",
    "    'GEN':'GENERAL',\n",
    "    'ADMN':'ADMINISTRATIVE',\n",
    "    'ENG':'ENGINEER',\n",
    "    'STRUCT':'STRUCTURAL',\n",
    "    'FRPRS':'FOREPERSON',\n",
    "    'FRPR':'FOREPERSON',\n",
    "    'FOREPRS':'FOREPERSON',\n",
    "    'CONST':'CONSTRUCTION',\n",
    "    'LBR':'LABORER',\n",
    "    'RPR':'REPAIR',\n",
    "    'REP':'REPAIR',\n",
    "    'SPEC':'SPECIAL',\n",
    "    'INCT COMND SP':'INCIDENT COMMAND SPECIALIST',\n",
    "    'MAS OF F BOAT':'MASTER OF FIRE BOAT',\n",
    "    'RPPRS':'REPAIRPERSON',\n",
    "    'REPPRS':'REPAIRPERSON',\n",
    "    'REPRPRS':'REPAIRPERSON',\n",
    "    'REPAIRPR':'REPAIRPERSON',\n",
    "    'REPAIRPRS':'REPAIRPERSON',\n",
    "    'RPPR':'REPAIR PERSON',\n",
    "    'WKG':'WORKING',\n",
    "    'PW':'PUBLIC WORKS',\n",
    "    'P W':'PUBLIC WORKS',\n",
    "    'HVY':'HEAVY',\n",
    "    'MTR':'MOTOR',\n",
    "    'INSP':'INSPECTOR',\n",
    "    'INSPEC':'INSPECTOR',\n",
    "    'TRA':'TRAFFIC',\n",
    "    'OPR':'OPERATIONS',\n",
    "    'MEO':'MOTOR EQUIPMENT OPERATOR',\n",
    "    'CFM':'(CFM)',\n",
    "    'ELEC EQUIPMENT':'ELECTRIC EQUIPMENT',\n",
    "    'ACC MANAGEMENT':'ACCOUNT MANAGEMENT',\n",
    "    'EQUI':'EQUIPMENT',\n",
    "    'COLL TRS':'COLLECTOR TREASURER',\n",
    "    'ACNTNG':'ACCOUNTING',\n",
    "    'CRFTSPRS':'CRAFTSPERSON',\n",
    "    'COUNSLR':'COUNSELOR',\n",
    "    'MEMBER BD OF ELECTION':'MEMBER OF BOARD OF ELECTIONS',\n",
    "    'LIB':'LIBRARIAN',\n",
    "    'LIBR':'LIBRARIAN',\n",
    "    'LIBRARIN':'LIBRARIAN',\n",
    "    'SVCS':'SERVICES',\n",
    "    'CAMP JO':'(CAMP JOY)',\n",
    "    'CAM JO':'(CAMP JOY)',\n",
    "    'SER':'SERVICES',\n",
    "    'PROT':'PROTECTIVE',\n",
    "    'REL':'RELATIONS',\n",
    "    'SUPVISING':'SUPERVISING',\n",
    "    'PROP':'PROPERTY',\n",
    "    'DISP':'DISPATCHER',\n",
    "    'CHF':'CHIEF',\n",
    "    'PMDGRAFF REMOVAL':'(PMD GRAFFITI REMOVAL)',\n",
    "    '(PAINT)':'& PAINTER',\n",
    "    '(PAINTER)':'& PAINTER',\n",
    "    'ENFORCE':'ENFORCEMENT',\n",
    "    'DEVELOP':'DEVELOPMENT',\n",
    "    'PROG':'PROGRAM',\n",
    "    'CONTRUCTION':'CONSTRUCTION',\n",
    "    'PWD':' (PWD)',\n",
    "    'SWIM':'SWIMMING',\n",
    "    'REGNL':'REGIONAL',\n",
    "    'ACCTNG':'ACCOUNTING',\n",
    "    'ENGR':'ENGINEER',\n",
    "    'EQU':'EQUIPMENT',\n",
    "    'EQ':'EQUIPMENT',\n",
    "    'ANIM CNTL OFCR':'ANIMAL CONTROL OFFICER',\n",
    "    'CLRK':'CLERK',\n",
    "    'DEVELOP':'DEVELOPMENT',\n",
    "    'PARKS & RECREATION':'PARKS & REC',\n",
    "    'P & R':'PARKS & REC',\n",
    "    '\\(PARK\\)':'(PARKS & REC)',\n",
    "    'SPC':'SPECIAL',\n",
    "    'HDQ':'HEADQUARTER',\n",
    "    'DISPCH':'DISPATCHER',\n",
    "    'SUB':'SUBSTITUTE',\n",
    "    'HE':'(HE)',\n",
    "    'FGR PRT EV':'FINGERPRINT EVIDENCE',\n",
    "    'CH':'CHIEF',\n",
    "    'OP':'OPERATOR',\n",
    "    'IBPDFLEET':'I (BPD FLEET',\n",
    "    'EVIDENC TECHNCN':'EVIDENCE TECHNICIAN',\n",
    "    'TCH':\"TECHNICIAN\"\n",
    "}\n",
    "\n",
    "abbrevs_regex = {}\n",
    "\n",
    "for key in abbrevs:\n",
    "    abbrevs[key] = ' '+abbrevs[key]+' '\n",
    "    new_key = '(^|[\\s\\(\\)\\-])'+key+'([\\s\\(\\)\\-]|$)'\n",
    "    abbrevs_regex[new_key] = abbrevs[key]\n",
    "\n",
    "earnings_df['Title'] = earnings_df['Title'].replace(abbrevs_regex, regex=True).str.strip()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_df[['Department', 'Name', 'Title', 'Postal']].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_title = earnings_df['Title'].str.split(\"(\", n=1, expand=True)\n",
    "new_title[0] = new_title[0].str.strip()\n",
    "new_title[1] = new_title[1].replace({'\\(':'','\\)':''}, regex=True).str.strip()\n",
    "#print(new_title)\n",
    "earnings_df['Title'] = (new_title[0].astype(str)+ ' (' + new_title[1].astype(str) + ')').replace('\\(None\\)', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_df.loc[earnings_df['Department'] == 'Boston Police Department', ['Department', 'Name', 'Title', 'Postal']].tail(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_df.loc[earnings_df['Department'] == 'Boston Police Department', ['Name', 'Title', 'Subtitle']].head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create pivot table displaying the number of people in each dept by year\n",
    "BPS_str = '^BPS|Elementary|Academy|K-8|Middle|High|School|Acad$|Pilot| EEC$| ELC$| EES$|9-12|Achievement Gap|Student'\n",
    "\n",
    "\n",
    "#purpose: get pivot table of employee counts by department\n",
    "    #column indicates what column to count on (i.e. Injured or Total)\n",
    "    #dept is an optional column that specifies what department to filter on, set to everything by default\n",
    "def count_by_dept(column, dept=r'(.*?)'):\n",
    "    \n",
    "    #create dataframe with department, year, and counts\n",
    "    dept_counts = earnings_df.loc[earnings_df[column]>0].groupby(['Department', 'Year'])[column].count().reset_index(name=\"count\")\n",
    "    \n",
    "    #remove BPS schools from result\n",
    "    dept_counts = dept_counts.loc[dept_counts['Department'].str.contains(BPS_str, regex=True) == False]\n",
    "    \n",
    "    #create the pivot table table, with calculated sums for each row and column\n",
    "    dept_counts_table = pd.pivot_table(dept_counts, values='count', index='Department', columns='Year', aggfunc='sum', fill_value=0, margins=True).reset_index()\n",
    "    \n",
    "    #get rid of the calculated sums by row, doesn't make sense for time series data\n",
    "    return dept_counts_table.iloc[:,0:-1].loc[dept_counts_table['Department'].str.match(dept)]\n",
    "\n",
    "count_by_dept('Injured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arts & Cultural Development -> Office of Arts & Culture\n",
    "#Transportation Department -> Traffic Division\n",
    "#Women's Commission -> Women's Advancement\n",
    "#Dept of Voter Mobilization -> Election Division\n",
    "#Youth Fund -> Youth Engagement & Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purpose: get pivot table of aggregates by department\n",
    "    #column indicates what column to use for aggregation (i.e. Injured, Regular, Total, etc.)\n",
    "    #aggfunc is the aggregation function (mean, sum, max, min)\n",
    "    #dept is an optional column that specifies what department to filter on, set to everything by default\n",
    "def agg_by_dept(column, aggfunc, dept=r'(.*?)'):\n",
    "    \n",
    "    #create dataframe with department, year, and aggregate column\n",
    "    dept_costs = earnings_df.loc[earnings_df[column]>0].groupby(['Department', 'Year'])[column].agg(aggfunc).reset_index(name=\"Costs\")\n",
    "    \n",
    "    #remove BPS schools from result\n",
    "    dept_costs = dept_costs.loc[dept_costs['Department'].str.contains(BPS_str, regex=True) == False]\n",
    "    \n",
    "    #create the pivot table table, with calculated aggregate for each row and column\n",
    "    dept_costs_table = pd.pivot_table(dept_costs, values='Costs', index='Department', columns='Year', aggfunc = aggfunc, fill_value=0, margins=True).reset_index()\n",
    "    \n",
    "    #get rid of the calculated aggregate by row, doesn't make sense for time series data\n",
    "    return dept_costs_table.iloc[:,0:-1].loc[dept_costs_table['Department'].str.match(dept)]\n",
    "\n",
    "agg_by_dept('Injured', 'median', 'Boston Police Department|Boston Fire Department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purpose: get pivot table of employee counts by department and title\n",
    "    #column indicates what column to count on (i.e. Injured or Total)\n",
    "    #dept is an optional column that specifies what department to filter on, set to everything by default\n",
    "    #title is an optional column that specifies what title to filter on, set to everything by default, not reccommended without setting dept first\n",
    "def count_by_title(column, dept=r'(.*?)', title=r'(.*?)'):\n",
    "    \n",
    "    #create dataframe with title, year, and counts\n",
    "    job_counts = earnings_df.loc[earnings_df['Department'].str.match(dept)]\n",
    "    job_counts = job_counts.loc[job_counts[column]>0].groupby(['Title', 'Year'])[column].count().reset_index(name=\"count\")\n",
    "    \n",
    "    #create the pivot table table, with calculated sums for each row and column\n",
    "    job_counts_table = pd.pivot_table(job_counts, values='count', index='Title', columns='Year', aggfunc=np.sum, fill_value=0, margins=True).reset_index()\n",
    "    \n",
    "    #get rid of the calculated sums by row, doesn't make sense for time series data\n",
    "    return job_counts_table.loc[job_counts_table['Title'].str.match(title)].sort_values(by='All', ascending=False).iloc[:,0:-1]\n",
    "\n",
    "count_by_title('Injured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purpose: get pivot table of chosen aggregate by department and title\n",
    "    #column indicates what column to aggregate on (i.e. Injured, Regular, Total, etc.)\n",
    "    #dept is an optional column that specifies what department to filter on, set to everything by default\n",
    "    #title is an optional column that specifies what title to filter on, set to everything by default, not reccommended without setting dept first\n",
    "def agg_by_title(column, aggfunc, dept=r'(.*?)', title=r'(.*?)'):\n",
    "    \n",
    "    #create dataframe with title, year, and aggregate column\n",
    "    job_pay = earnings_df.loc[earnings_df['Department'].str.match(dept)].groupby(['Title', 'Year'])[column].agg(aggfunc).reset_index(name=\"Costs\")\n",
    "    \n",
    "    #create the pivot table table, with calculated aggregate for each row and column\n",
    "    job_pay_table = pd.pivot_table(job_pay, values='Costs', index='Title', columns='Year', fill_value=0, margins=True).reset_index()\n",
    "    \n",
    "    #get rid of the calculated sums by row, doesn't make sense for time series data\n",
    "    return job_pay_table.loc[job_pay_table['Title'].str.match(title)].sort_values(by='All', ascending=False).iloc[:,0:-1]\n",
    "\n",
    "agg_by_title('Total', 'mean', 'Mayor\\'s Office', 'Chief Diversity Officer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(earnings_df.loc[(earnings_df['Injured']>0) & (earnings_df['Year']==2014) & (earnings_df['Department']=='Boston Police Department'), ['Name', 'Title', 'Injured']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_title('Total', title='Prin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
